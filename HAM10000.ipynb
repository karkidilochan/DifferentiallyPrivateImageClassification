{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb341c81-f158-49b9-9814-4466dfdab957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from glob import glob\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from opacus.validators import ModuleValidator\n",
    "from opacus.accountants.utils import get_noise_multiplier\n",
    "from private_vision import PrivacyEngine\n",
    "import opacus\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import timm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39f6f9a-4671-4484-92f1-16ed99f44a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hmnist_8_8_RGB.csv', 'hmnist_28_28_L.csv', 'hmnist_28_28_RGB.csv', 'HAM10000_images_part_2', 'HAM10000_images_part_1', 'HAM10000_metadata.csv', 'hmnist_8_8_L.csv']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/s/lovelace/c/nobackup/iray/dp-imgclass/HAM10000_original'\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "011c0976-898f-4522-a26a-19eeebbf01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_path = glob(os.path.join(data_dir, '*', '*.jpg'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb5b80c-0314-429d-a6f3-96b7f61ee2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                                path  \\\n",
       "0  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "1  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "2  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "3  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "4  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "\n",
       "                        cell_type  cell_type_idx  \n",
       "0  Benign keratosis-like lesions               2  \n",
       "1  Benign keratosis-like lesions               2  \n",
       "2  Benign keratosis-like lesions               2  \n",
       "3  Benign keratosis-like lesions               2  \n",
       "4  Benign keratosis-like lesions               2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(os.path.join(data_dir, 'HAM10000_metadata.csv'))\n",
    "df_original['path'] = df_original['image_id'].map(imageid_path_dict.get)\n",
    "df_original['cell_type'] = df_original['dx'].map(lesion_type_dict.get)\n",
    "df_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279459f2-19d1-4851-ae90-419d614f9d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "      <th>duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>/s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                                path  \\\n",
       "0  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "1  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "2  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "3  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "4  /s/lovelace/c/nobackup/iray/dp-imgclass/HAM100...   \n",
       "\n",
       "                        cell_type  cell_type_idx  duplicates  \n",
       "0  Benign keratosis-like lesions               2  duplicated  \n",
       "1  Benign keratosis-like lesions               2  duplicated  \n",
       "2  Benign keratosis-like lesions               2  duplicated  \n",
       "3  Benign keratosis-like lesions               2  duplicated  \n",
       "4  Benign keratosis-like lesions               2  duplicated  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_undup = df_original.groupby('lesion_id').count()\n",
    "# now we filter out lesion_id's that have only one image associated with it\n",
    "df_undup = df_undup[df_undup['image_id'] == 1]\n",
    "df_undup.reset_index(inplace=True)\n",
    "def get_duplicates(x):\n",
    "    unique_list = list(df_undup['lesion_id'])\n",
    "    if x in unique_list:\n",
    "        return 'unduplicated'\n",
    "    else:\n",
    "        return 'duplicated'\n",
    "\n",
    "# create a new colum that is a copy of the lesion_id column\n",
    "df_original['duplicates'] = df_original['lesion_id']\n",
    "# apply the function to this new column\n",
    "df_original['duplicates'] = df_original['duplicates'].apply(get_duplicates)\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456ba4e1-2e39-4e2f-ab66-77f83ab9df4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5514, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_undup = df_original[df_original['duplicates'] == 'unduplicated']\n",
    "df_undup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c896b4c7-2e1a-477d-b0ff-c0acd10ae91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1103, 11),\n",
       " cell_type_idx\n",
       " 4    883\n",
       " 2     88\n",
       " 5     46\n",
       " 1     35\n",
       " 0     30\n",
       " 6     13\n",
       " 3      8\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_undup['cell_type_idx']\n",
    "_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\n",
    "df_val.shape, df_val['cell_type_idx'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1aa6886d-25b3-4a22-8c56-efba9973aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8912\n",
      "1103\n"
     ]
    }
   ],
   "source": [
    "# This set will be df_original excluding all rows that are in the val set\n",
    "# This function identifies if an image is part of the train or val set.\n",
    "def get_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image_id'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# identify train and val rows\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_original['train_or_val'] = df_original['image_id']\n",
    "# apply the function to this new column\n",
    "df_original['train_or_val'] = df_original['train_or_val'].apply(get_val_rows)\n",
    "# filter out train rows\n",
    "df_train = df_original[df_original['train_or_val'] == 'train']\n",
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39b29e08-4972-4e20-a669-9d31c26b85be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell_type\n",
       "Melanocytic nevi                  5822\n",
       "Melanoma                          1067\n",
       "Benign keratosis-like lesions     1011\n",
       "Basal cell carcinoma               479\n",
       "Actinic keratoses                  297\n",
       "Vascular lesions                   129\n",
       "Dermatofibroma                     107\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae7bd145-4630-48da-9dfb-ffee9df86ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell_type_idx\n",
       "4    5822\n",
       "5    1067\n",
       "2    1011\n",
       "1     479\n",
       "0     297\n",
       "6     129\n",
       "3     107\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88fe1b9b-4ac0-448b-9f23-5c3ef8d2a921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell_type\n",
       "Melanocytic nevi                  883\n",
       "Benign keratosis-like lesions      88\n",
       "Melanoma                           46\n",
       "Basal cell carcinoma               35\n",
       "Actinic keratoses                  30\n",
       "Vascular lesions                   13\n",
       "Dermatofibroma                      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6224733-3347-421f-9d87-50e727d27543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell_type_idx\n",
       "4    883\n",
       "2     88\n",
       "5     46\n",
       "1     35\n",
       "0     30\n",
       "6     13\n",
       "3      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46fde61a-ba87-45e7-8281-c4a69131313e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell_type\n",
       "Melanocytic nevi                  883\n",
       "Benign keratosis-like lesions     880\n",
       "Basal cell carcinoma              875\n",
       "Vascular lesions                  871\n",
       "Actinic keratoses                 840\n",
       "Melanoma                          828\n",
       "Dermatofibroma                    800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27399362-f175-40ab-8b3d-b9a1a85afa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_aug_rate = [15,10,5,50,0,5,40]\n",
    "for i in range(7):\n",
    "    if traindata_aug_rate[i]:\n",
    "        aug_list = [df_train.loc[df_train['cell_type_idx'] == i,:]]*(traindata_aug_rate[i]-1)\n",
    "        aug_df = pd.concat(aug_list)\n",
    "        df_train = pd.concat([df_train, aug_df])\n",
    "\n",
    "df_train = df_train.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48cae1af-882b-45ad-8e89-68c7915de548",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata_aug_rate = [28,25,10,100,0,18,67]\n",
    "for i in range(7):\n",
    "    if testdata_aug_rate[i]:\n",
    "        aug_list = [df_val.loc[df_val['cell_type_idx'] == i,:]]*(testdata_aug_rate[i]-1)\n",
    "        aug_df = pd.concat(aug_list)\n",
    "        df_val = pd.concat([df_val, aug_df])\n",
    "\n",
    "df_val = df_val.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee670c8e-6699-4100-857c-e089e531e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.Resize((224,224)),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor()])\n",
    "\n",
    "class HAM10000(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "trainset = HAM10000(df_train, transform=train_transform)\n",
    "# Same for the validation set:\n",
    "testset = HAM10000(df_val, transform=train_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bbcce57-22d4-4e1d-833b-9619ff91c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(args):\n",
    "    print('==> Building model..', args.model, '  mode ', args.mode)\n",
    "    device=torch.device(\"cuda\")\n",
    "    NUM_CLASSES=7\n",
    "    trainloader = DataLoader(trainset, batch_size=args.mini_bs, shuffle=True, num_workers=4)\n",
    "    testloader = DataLoader(testset, batch_size=args.mini_bs, shuffle=False, num_workers=4)\n",
    "\n",
    "    net = timm.create_model(args.model, pretrained=args.pretrained, num_classes=NUM_CLASSES)\n",
    "\n",
    "    # \n",
    "    net = ModuleValidator.fix(net)\n",
    "    net = net.to(device)\n",
    "\n",
    "    if 'xcit' in args.model:\n",
    "      for name,param in net.named_parameters():\n",
    "          if 'gamma' in name or 'attn.temperature' in name:\n",
    "            param.requires_grad=False\n",
    " \n",
    "    if 'cait' in args.model:\n",
    "      for name,param in net.named_parameters():\n",
    "          if 'gamma_' in name:\n",
    "            param.requires_grad=False\n",
    "\n",
    "    if 'convnext' in args.model:\n",
    "        for name,param in net.named_parameters():\n",
    "            if '.gamma' in name or 'head.norm.' in name or 'downsample.0' in name or 'stem.1' in name:\n",
    "                param.requires_grad=False\n",
    "\n",
    "    if 'convit' in args.model:\n",
    "        for name,param in net.named_parameters():\n",
    "            if 'attn.gating_param' in name:\n",
    "                param.requires_grad=False\n",
    "\n",
    "    if 'beit' in args.model:\n",
    "        for name,param in net.named_parameters():\n",
    "            if 'gamma_' in name or 'relative_position_bias_table' in name or 'attn.qkv.weight' in name or 'attn.q_bias' in name or 'attn.v_bias' in name:\n",
    "                param.requires_grad=False\n",
    "\n",
    "    for name,param in net.named_parameters():\n",
    "        if 'cls_token' in name or 'pos_embed' in name:\n",
    "            param.requires_grad=False\n",
    "\n",
    "    print('number of parameters: ', sum([p.numel() for p in net.parameters()]))\n",
    "\n",
    "    if \"ghost\" in args.mode:\n",
    "        criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
    "\n",
    "    n_acc_steps = args.bs // args.mini_bs\n",
    "\n",
    "    if 'ghost' in args.mode:\n",
    "        sigma = get_noise_multiplier(\n",
    "                target_epsilon = args.eps,\n",
    "                target_delta = 1e-5,\n",
    "                sample_rate = args.bs/len(trainset),\n",
    "                epochs = args.epochs,\n",
    "                accountant = \"gdp\"\n",
    "            )\n",
    "        privacy_engine = PrivacyEngine(\n",
    "            net,\n",
    "            batch_size=args.bs,\n",
    "            sample_size=len(trainloader.dataset),\n",
    "            noise_multiplier=sigma,\n",
    "            epochs=args.epochs,\n",
    "            max_grad_norm=args.grad_norm,\n",
    "            ghost_clipping='non' not in args.mode,\n",
    "            mixed='mixed' in args.mode\n",
    "        )\n",
    "        privacy_engine.attach(optimizer)\n",
    "\n",
    "    def train(epoch):\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(trainloader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            if args.mode=='non-private':\n",
    "                loss.backward()\n",
    "                if ((batch_idx + 1) % n_acc_steps == 0) or ((batch_idx + 1) == len(trainloader)):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "            else:\n",
    "                if ((batch_idx + 1) % n_acc_steps == 0) or ((batch_idx + 1) == len(trainloader)):\n",
    "                    optimizer.step(loss=loss)\n",
    "                    optimizer.zero_grad()\n",
    "                else:\n",
    "                    optimizer.virtual_step(loss=loss)\n",
    "            train_loss += loss.mean().item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print(epoch, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        return train_loss/(batch_idx+1), 100.*correct/total\n",
    "\n",
    "    \n",
    "    def test(epoch):\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(tqdm(testloader)):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                loss = loss.mean()\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            print(epoch, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "            return test_loss/(batch_idx+1), 100.*correct/total\n",
    "    def save_model(filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(net, f)\n",
    "            # torch.save(net,f)\n",
    "\n",
    "    return args.epochs, train, test, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ae38c05-576d-4044-9219-1a683699a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(epochs, trainf, testf, args):\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_accuracy = trainf(epoch)\n",
    "        test_loss, test_accuracy = testf(epoch)\n",
    "    return train_loss, train_accuracy, test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d89627a8-2d01-46a7-b51f-2cd4361d967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  non-ghost\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.001, epochs=5, batch_size=1600, epsilon=2, grad_norm=0.5, mode='non-ghost', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=10, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3597 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Parameter' object has no attribute 'grad_sample'\n *** patch_embed.proj.weight parameter has no grad_sample attribute ***",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 78\u001b[0m\n\u001b[1;32m     76\u001b[0m epochs, trainf, testf, save_modelf \u001b[38;5;241m=\u001b[39m prepare(args)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning experiment with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m train_loss, train_accuracy, test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(epochs, trainf, testf, args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(epochs, trainf, testf, args):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 3\u001b[0m         train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrainf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m testf(epoch)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loss, train_accuracy, test_loss, test_accuracy\n",
      "Cell \u001b[0;32mIn[42], line 96\u001b[0m, in \u001b[0;36mprepare.<locals>.train\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     94\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvirtual_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     98\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/private_vision/privacy_engine.py:207\u001b[0m, in \u001b[0;36mPrivacyEngine.attach.<locals>.virtual_step\u001b[0;34m(_self, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvirtual_step\u001b[39m(_self, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 207\u001b[0m     \u001b[43m_self\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprivacy_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvirtual_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/venv/lib64/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/private_vision/privacy_engine.py:389\u001b[0m, in \u001b[0;36mPrivacyEngine.virtual_step\u001b[0;34m(self, scale, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ghost_virtual_step(loss\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_virtual_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/private_vision/privacy_engine.py:468\u001b[0m, in \u001b[0;36mPrivacyEngine._virtual_step\u001b[0;34m(self, loss, scale)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_virtual_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m):\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accumulate_summed_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_params:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;66;03m# Del everything except `.summed_grad` to save memory!\u001b[39;00m\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(param, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    472\u001b[0m             \u001b[38;5;66;03m# This must be deleted due to how `privacy_utils::supported_layers_grad_samplers.py` works!\u001b[39;00m\n\u001b[1;32m    473\u001b[0m             \u001b[38;5;66;03m#   When a parameter with `.grad_sample` is reused, the per-sample gradients are accumulated!\u001b[39;00m\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/venv/lib64/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/private_vision/privacy_engine.py:494\u001b[0m, in \u001b[0;36mPrivacyEngine._accumulate_summed_grad\u001b[0;34m(self, loss, scale)\u001b[0m\n\u001b[1;32m    492\u001b[0m     extra_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m *** \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m parameter has no grad_sample attribute ***\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    493\u001b[0m     error\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m extra_msg, \u001b[38;5;241m*\u001b[39margs[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    495\u001b[0m norm \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mgrad_sample\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    496\u001b[0m norm_sample\u001b[38;5;241m.\u001b[39mappend(norm\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/private_vision/privacy_engine.py:489\u001b[0m, in \u001b[0;36mPrivacyEngine._accumulate_summed_grad\u001b[0;34m(self, loss, scale)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_params:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_sample\u001b[49m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    491\u001b[0m         args \u001b[38;5;241m=\u001b[39m error\u001b[38;5;241m.\u001b[39margs\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Parameter' object has no attribute 'grad_sample'\n *** patch_embed.proj.weight parameter has no grad_sample attribute ***"
     ]
    }
   ],
   "source": [
    "# block for Non private training\n",
    "\n",
    "class Arguments:\n",
    "    def __init__(self, learning_rate, epochs, batch_size, epsilon, grad_norm, mode, model, mini_batch_size, pretrained):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.bs = batch_size\n",
    "        self.eps = epsilon\n",
    "        self.grad_norm = grad_norm\n",
    "        self.mode = mode\n",
    "        self.model = model\n",
    "        self.mini_bs = mini_batch_size\n",
    "        self.pretrained = pretrained\n",
    "    def __str__(self):\n",
    "        return f\"Arguments(learning_rate={self.lr}, epochs={self.epochs}, batch_size={self.bs}, epsilon={self.eps}, grad_norm={self.grad_norm}, mode='{self.mode}', model='{self.model}', mini_batch_size={self.mini_bs}, pretrained={self.pretrained})\"\n",
    "\n",
    "results = [['Epsilon', 'Grad Norm', 'Mini Batch Size', 'Train Loss', 'Train Accuracy', 'Test Loss', 'Test Accuracy']]\n",
    "epsilons = [0.5, 1, 2]\n",
    "batch_sizes = [800, 1600]\n",
    "epochs_to_test = [5, 10]\n",
    "mini_batches = [10,20]\n",
    "learning_rates = []\n",
    "\n",
    "# batch_sizes = [500]\n",
    "# epochs_to_test = [5]\n",
    "\n",
    "# for batch_size in batch_sizes:\n",
    "#     for epoch in epochs_to_test:\n",
    "#         # Modify any additional variables here (or put them into their own loop like above)\n",
    "#         args = Arguments(learning_rate=1e-4,\n",
    "#                         epochs=epoch,\n",
    "#                         batch_size=batch_size,\n",
    "#                         epsilon=1,\n",
    "#                         grad_norm=0.5,\n",
    "#                         mode='non-private',\n",
    "#                         model='beit_base_patch16_224.in22k_ft_in22k',\n",
    "#                         mini_batch_size=10,\n",
    "#                         pretrained=1)\n",
    "#         epochs, trainf, testf, save_modelf = prepare(args)\n",
    "#         print(f\"Running experiment with: {args}\")\n",
    "#         train_loss, train_accuracy, test_loss, test_accuracy = main(epochs, trainf, testf, args)\n",
    "#         results.append([batch_size, epoch, train_loss, train_accuracy, test_loss, test_accuracy])\n",
    "#     with open(f\"ham_results/results_non-private_{args.bs}_{args.eps}_{args.mini_bs}.json\", 'w') as result_file:\n",
    "#             result_file.write(json.dumps(results))\n",
    "\n",
    "# for batch_size in batch_sizes:\n",
    "#     for epsilon in epsilons:\n",
    "#         for mini_bs in mini_batches:\n",
    "#             for epoch in epochs_to_test:\n",
    "#                 # Modify any additional variables here (or put them into their own loop like above)\n",
    "#                 args = Arguments(learning_rate=1e-3,\n",
    "#                                 epochs=epoch,\n",
    "#                                 batch_size=batch_size,\n",
    "#                                 epsilon=epsilon,\n",
    "#                                 grad_norm=0.5,\n",
    "#                                 mode='ghost_mixed',\n",
    "#                                 model='beit_base_patch16_224.in22k_ft_in22k',\n",
    "#                                 mini_batch_size=mini_bs,\n",
    "#                                 pretrained=0)\n",
    "#                 epochs, trainf, testf, save_modelf = prepare(args)\n",
    "#                 print(f\"Running experiment with: {args}\")\n",
    "#                 train_loss, train_accuracy, test_loss, test_accuracy = main(epochs, trainf, testf, args)\n",
    "#                 results.append([epsilon, 0.5, mini_bs, train_loss, train_accuracy, test_loss, test_accuracy])\n",
    "#             with open(f\"ham_results/results_no-pretrained_{args.bs}_{args.eps}_{args.mini_bs}.json\", 'w') as result_file:\n",
    "#                     result_file.write(json.dumps(results))\n",
    "\n",
    "args = Arguments(learning_rate=1e-3,\n",
    "                epochs=5,\n",
    "                batch_size=1600,\n",
    "                epsilon=2,\n",
    "                grad_norm=0.5,\n",
    "                mode='non-ghost',\n",
    "                model='beit_base_patch16_224.in22k_ft_in22k',\n",
    "                mini_batch_size=10,\n",
    "                pretrained=1)\n",
    "epochs, trainf, testf, save_modelf = prepare(args)\n",
    "print(f\"Running experiment with: {args}\")\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = main(epochs, trainf, testf, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa8705b1-3d69-4bea-921e-3ab38d72a1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.001, epochs=5, batch_size=800, epsilon=0.5, grad_norm=0.5, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=10, pretrained=0)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:51<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.933 | Acc: 18.008% (6477/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 1.922 | Acc: 22.536% (1347/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:06<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 1.903 | Acc: 20.869% (7506/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 1.885 | Acc: 21.700% (1297/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 1.879 | Acc: 23.180% (8337/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 1.847 | Acc: 27.857% (1665/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:03<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 1.855 | Acc: 25.040% (9006/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 1.825 | Acc: 27.957% (1671/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:06<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 1.844 | Acc: 25.507% (9174/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 1.797 | Acc: 31.320% (1872/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.001, epochs=10, batch_size=800, epsilon=0.5, grad_norm=0.5, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=10, pretrained=0)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:06<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.934 | Acc: 17.722% (6374/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 1.926 | Acc: 17.735% (1060/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:03<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 1.916 | Acc: 19.379% (6970/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 1.895 | Acc: 23.791% (1422/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:03<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 1.893 | Acc: 22.351% (8039/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 1.872 | Acc: 22.034% (1317/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:03<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 1.876 | Acc: 23.296% (8379/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 1.849 | Acc: 28.091% (1679/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:02<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 1.859 | Acc: 24.342% (8755/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 1.837 | Acc: 27.957% (1671/5977)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:01<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3597 Loss: 1.847 | Acc: 25.006% (8994/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 598 Loss: 1.824 | Acc: 28.710% (1716/5977)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:08<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3597 Loss: 1.845 | Acc: 25.940% (9330/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 598 Loss: 1.833 | Acc: 27.505% (1644/5977)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:05<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3597 Loss: 1.847 | Acc: 26.032% (9363/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 598 Loss: 1.823 | Acc: 31.738% (1897/5977)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:02<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3597 Loss: 1.846 | Acc: 26.877% (9667/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 598 Loss: 1.829 | Acc: 28.911% (1728/5977)\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:02<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3597 Loss: 1.848 | Acc: 26.911% (9679/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 598 Loss: 1.865 | Acc: 31.086% (1858/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.001, epochs=5, batch_size=800, epsilon=0.5, grad_norm=0.5, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=20, pretrained=0)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1799/1799 [08:12<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1799 Loss: 1.932 | Acc: 17.755% (6386/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:21<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 299 Loss: 1.908 | Acc: 23.005% (1375/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1799/1799 [08:12<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1799 Loss: 1.906 | Acc: 20.555% (7393/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:22<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 299 Loss: 1.887 | Acc: 18.387% (1099/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1799/1799 [08:14<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1799 Loss: 1.880 | Acc: 22.904% (8238/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:21<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 299 Loss: 1.850 | Acc: 28.593% (1709/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1799/1799 [08:13<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1799 Loss: 1.858 | Acc: 24.314% (8745/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:21<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 299 Loss: 1.836 | Acc: 24.226% (1448/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1799/1799 [08:20<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1799 Loss: 1.851 | Acc: 25.407% (9138/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 152/299 [00:12<00:11, 12.51it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m     epochs, trainf, testf, save_modelf \u001b[38;5;241m=\u001b[39m prepare(args)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning experiment with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m     train_loss, train_accuracy, test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend([epsilon, \u001b[38;5;241m0.5\u001b[39m, mini_bs, train_loss, train_accuracy, test_loss, test_accuracy])\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mham_results/results_no-pretrained_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mbs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39meps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mmini_bs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m result_file:\n",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(epochs, trainf, testf, args)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m trainf(epoch)\n\u001b[0;32m----> 4\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtestf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss, train_accuracy, test_loss, test_accuracy\n",
      "Cell \u001b[0;32mIn[15], line 119\u001b[0m, in \u001b[0;36mprepare.<locals>.test\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    116\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m    118\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m--> 119\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    121\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "class Arguments:\n",
    "    def __init__(self, learning_rate, epochs, batch_size, epsilon, grad_norm, mode, model, mini_batch_size, pretrained):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.bs = batch_size\n",
    "        self.eps = epsilon\n",
    "        self.grad_norm = grad_norm\n",
    "        self.mode = mode\n",
    "        self.model = model\n",
    "        self.mini_bs = mini_batch_size\n",
    "        self.pretrained = pretrained\n",
    "    def __str__(self):\n",
    "        return f\"Arguments(learning_rate={self.lr}, epochs={self.epochs}, batch_size={self.bs}, epsilon={self.eps}, grad_norm={self.grad_norm}, mode='{self.mode}', model='{self.model}', mini_batch_size={self.mini_bs}, pretrained={self.pretrained})\"\n",
    "\n",
    "results = [['Epsilon', 'Grad Norm', 'Mini Batch Size', 'Train Loss', 'Train Accuracy', 'Test Loss', 'Test Accuracy']]\n",
    "epsilons = [0.5, 1, 2]\n",
    "batch_sizes = [800, 1600]\n",
    "epochs_to_test = [5, 10]\n",
    "mini_batches = [10,20]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for epsilon in epsilons:\n",
    "        for mini_bs in mini_batches:\n",
    "            for epoch in epochs_to_test:\n",
    "                # Modify any additional variables here (or put them into their own loop like above)\n",
    "                args = Arguments(learning_rate=1e-3,\n",
    "                                epochs=epoch,\n",
    "                                batch_size=batch_size,\n",
    "                                epsilon=epsilon,\n",
    "                                grad_norm=0.5,\n",
    "                                mode='ghost_mixed',\n",
    "                                model='beit_base_patch16_224.in22k_ft_in22k',\n",
    "                                mini_batch_size=mini_bs,\n",
    "                                pretrained=0)\n",
    "                epochs, trainf, testf, save_modelf = prepare(args)\n",
    "                print(f\"Running experiment with: {args}\")\n",
    "                train_loss, train_accuracy, test_loss, test_accuracy = main(epochs, trainf, testf, args)\n",
    "                results.append([epsilon, 0.5, mini_bs, train_loss, train_accuracy, test_loss, test_accuracy])\n",
    "            with open(f\"ham_results/results_no-pretrained_{args.bs}_{args.eps}_{args.mini_bs}.json\", 'w') as result_file:\n",
    "                    result_file.write(json.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "148f4bfb-a2ce-410a-a5d4-fab5b579178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.002, epochs=10, batch_size=500, epsilon=0.5, grad_norm=0.1, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=100, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.916 | Acc: 20.814% (7486/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 1.873 | Acc: 22.352% (1336/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 1.878 | Acc: 24.353% (8759/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 27.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 1.848 | Acc: 27.823% (1663/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 1.876 | Acc: 24.322% (8748/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 1.840 | Acc: 26.251% (1569/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 1.868 | Acc: 24.144% (8684/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 1.864 | Acc: 25.514% (1525/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 1.876 | Acc: 23.872% (8586/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 1.933 | Acc: 21.767% (1301/5977)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3597 Loss: 1.873 | Acc: 23.157% (8329/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 27.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 598 Loss: 1.842 | Acc: 28.928% (1729/5977)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3597 Loss: 1.861 | Acc: 24.183% (8698/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 598 Loss: 1.814 | Acc: 27.723% (1657/5977)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3597 Loss: 1.873 | Acc: 24.041% (8647/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 598 Loss: 1.885 | Acc: 24.695% (1476/5977)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3597 Loss: 1.861 | Acc: 24.928% (8966/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 27.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 598 Loss: 1.893 | Acc: 24.025% (1436/5977)\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3597 Loss: 1.856 | Acc: 25.126% (9037/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 598 Loss: 1.885 | Acc: 26.184% (1565/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.002, epochs=10, batch_size=500, epsilon=0.5, grad_norm=0.1, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=250, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.957 | Acc: 16.429% (5909/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 2.043 | Acc: 16.011% (957/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 1.930 | Acc: 20.405% (7339/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 1.875 | Acc: 22.737% (1359/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 1.904 | Acc: 21.531% (7744/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 1.927 | Acc: 23.072% (1379/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 1.929 | Acc: 20.930% (7528/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 1.894 | Acc: 20.462% (1223/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 1.933 | Acc: 21.219% (7632/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 1.837 | Acc: 24.243% (1449/5977)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3597 Loss: 1.936 | Acc: 21.175% (7616/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 598 Loss: 1.921 | Acc: 22.988% (1374/5977)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3597 Loss: 1.923 | Acc: 21.411% (7701/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 598 Loss: 1.869 | Acc: 23.875% (1427/5977)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3597 Loss: 1.943 | Acc: 20.702% (7446/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 598 Loss: 1.935 | Acc: 20.044% (1198/5977)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3597 Loss: 1.951 | Acc: 20.057% (7214/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 598 Loss: 1.923 | Acc: 19.424% (1161/5977)\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3597 Loss: 1.907 | Acc: 21.767% (7829/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 598 Loss: 1.869 | Acc: 25.765% (1540/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.002, epochs=10, batch_size=500, epsilon=0.5, grad_norm=0.1, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=500, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.986 | Acc: 16.140% (5805/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 2.005 | Acc: 13.786% (824/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 1.990 | Acc: 18.169% (6535/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 2.098 | Acc: 18.203% (1088/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:11<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 1.976 | Acc: 19.168% (6894/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 1.960 | Acc: 18.270% (1092/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:11<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 2.016 | Acc: 15.984% (5749/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 1.952 | Acc: 14.723% (880/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 2.010 | Acc: 16.362% (5885/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 27.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 1.963 | Acc: 19.843% (1186/5977)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3597 Loss: 1.985 | Acc: 18.959% (6819/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 598 Loss: 2.218 | Acc: 16.697% (998/5977)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3597 Loss: 2.047 | Acc: 17.277% (6214/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 598 Loss: 1.920 | Acc: 25.046% (1497/5977)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3597 Loss: 1.997 | Acc: 18.025% (6483/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 598 Loss: 1.945 | Acc: 17.283% (1033/5977)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:09<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3597 Loss: 2.032 | Acc: 16.821% (6050/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 598 Loss: 2.104 | Acc: 20.077% (1200/5977)\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:09<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3597 Loss: 2.005 | Acc: 17.597% (6329/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 598 Loss: 1.900 | Acc: 24.377% (1457/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.002, epochs=10, batch_size=500, epsilon=0.5, grad_norm=0.5, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=100, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:20<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.929 | Acc: 20.213% (7270/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 1.928 | Acc: 22.269% (1331/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:20<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 1.899 | Acc: 23.296% (8379/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 1.899 | Acc: 21.315% (1274/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 1.896 | Acc: 21.831% (7852/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 1.925 | Acc: 17.718% (1059/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 1.879 | Acc: 24.011% (8636/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 1.898 | Acc: 24.025% (1436/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 1.884 | Acc: 23.419% (8423/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 1.911 | Acc: 27.505% (1644/5977)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3597 Loss: 1.864 | Acc: 25.674% (9234/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 598 Loss: 1.805 | Acc: 28.459% (1701/5977)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3597 Loss: 1.845 | Acc: 25.098% (9027/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 598 Loss: 1.854 | Acc: 27.740% (1658/5977)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3597 Loss: 1.839 | Acc: 26.241% (9438/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 598 Loss: 1.837 | Acc: 26.686% (1595/5977)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3597 Loss: 1.824 | Acc: 26.969% (9700/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 598 Loss: 1.929 | Acc: 28.074% (1678/5977)\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3597 Loss: 1.805 | Acc: 27.698% (9962/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 598 Loss: 1.841 | Acc: 29.664% (1773/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.002, epochs=10, batch_size=500, epsilon=0.5, grad_norm=0.5, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=250, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.963 | Acc: 18.528% (6664/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 1.978 | Acc: 22.319% (1334/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 1.938 | Acc: 20.191% (7262/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 1.971 | Acc: 21.399% (1279/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 1.931 | Acc: 19.896% (7156/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 2.006 | Acc: 17.969% (1074/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 1.944 | Acc: 19.988% (7189/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 1.925 | Acc: 22.403% (1339/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 1.947 | Acc: 19.209% (6909/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 1.881 | Acc: 22.754% (1360/5977)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3597 Loss: 1.936 | Acc: 20.419% (7344/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 598 Loss: 2.012 | Acc: 17.216% (1029/5977)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3597 Loss: 1.927 | Acc: 21.662% (7791/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 598 Loss: 1.957 | Acc: 21.031% (1257/5977)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3597 Loss: 1.934 | Acc: 20.663% (7432/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 598 Loss: 1.895 | Acc: 22.737% (1359/5977)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3597 Loss: 1.911 | Acc: 23.018% (8279/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 598 Loss: 1.885 | Acc: 25.933% (1550/5977)\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3597 Loss: 1.926 | Acc: 22.573% (8119/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 598 Loss: 1.883 | Acc: 26.686% (1595/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.002, epochs=10, batch_size=500, epsilon=0.5, grad_norm=0.5, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=500, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.999 | Acc: 15.044% (5411/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 2.032 | Acc: 8.098% (484/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:11<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 2.007 | Acc: 15.542% (5590/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 2.032 | Acc: 14.388% (860/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:11<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 2.025 | Acc: 15.637% (5624/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 2.044 | Acc: 21.717% (1298/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 2.019 | Acc: 17.666% (6354/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 2.100 | Acc: 14.807% (885/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 2.020 | Acc: 18.461% (6640/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 2.100 | Acc: 12.515% (748/5977)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:11<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3597 Loss: 1.999 | Acc: 19.476% (7005/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 598 Loss: 1.966 | Acc: 20.596% (1231/5977)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:10<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3597 Loss: 2.007 | Acc: 19.087% (6865/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 598 Loss: 2.007 | Acc: 21.616% (1292/5977)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:11<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3597 Loss: 2.031 | Acc: 18.436% (6631/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 598 Loss: 1.932 | Acc: 20.462% (1223/5977)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:11<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3597 Loss: 1.999 | Acc: 21.100% (7589/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 598 Loss: 2.147 | Acc: 19.291% (1153/5977)\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [09:11<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3597 Loss: 1.992 | Acc: 20.772% (7471/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 598 Loss: 1.940 | Acc: 22.871% (1367/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.002, epochs=10, batch_size=500, epsilon=0.5, grad_norm=1, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=100, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.934 | Acc: 19.724% (7094/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 1.822 | Acc: 29.781% (1780/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 1.848 | Acc: 25.067% (9016/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 1.826 | Acc: 25.347% (1515/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 1.855 | Acc: 24.706% (8886/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 1.840 | Acc: 25.364% (1516/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 1.881 | Acc: 24.472% (8802/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 26.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 1.848 | Acc: 28.928% (1729/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 1.863 | Acc: 24.873% (8946/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 1.900 | Acc: 22.135% (1323/5977)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3597 Loss: 1.860 | Acc: 24.548% (8829/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 598 Loss: 1.904 | Acc: 22.001% (1315/5977)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3597 Loss: 1.854 | Acc: 25.965% (9339/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 598 Loss: 1.906 | Acc: 25.715% (1537/5977)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3597 Loss: 1.855 | Acc: 25.498% (9171/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 598 Loss: 1.805 | Acc: 28.359% (1695/5977)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:22<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3597 Loss: 1.873 | Acc: 25.234% (9076/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 598 Loss: 1.882 | Acc: 26.635% (1592/5977)\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:21<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3597 Loss: 1.861 | Acc: 25.059% (9013/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 598 Loss: 1.842 | Acc: 31.538% (1885/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.002, epochs=10, batch_size=500, epsilon=0.5, grad_norm=1, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=250, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3597 Loss: 1.958 | Acc: 18.270% (6571/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 598 Loss: 1.912 | Acc: 18.889% (1129/5977)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3597 Loss: 1.913 | Acc: 21.078% (7581/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 Loss: 1.927 | Acc: 20.579% (1230/5977)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3597 Loss: 1.914 | Acc: 21.511% (7737/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:22<00:00, 27.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 598 Loss: 1.900 | Acc: 23.256% (1390/5977)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3597 Loss: 1.915 | Acc: 22.526% (8102/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 598 Loss: 1.876 | Acc: 22.168% (1325/5977)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3597 Loss: 1.929 | Acc: 20.485% (7368/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 598 Loss: 1.959 | Acc: 19.240% (1150/5977)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3597 Loss: 1.924 | Acc: 20.980% (7546/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 598 Loss: 1.909 | Acc: 21.382% (1278/5977)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:40<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3597 Loss: 1.944 | Acc: 20.088% (7225/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 598 Loss: 1.964 | Acc: 19.575% (1170/5977)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3597 Loss: 1.946 | Acc: 19.582% (7043/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 598 Loss: 1.923 | Acc: 22.302% (1333/5977)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3597 Loss: 1.927 | Acc: 20.093% (7227/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 598 Loss: 1.918 | Acc: 20.763% (1241/5977)\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3597/3597 [08:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3597 Loss: 1.930 | Acc: 21.762% (7827/35967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598/598 [00:21<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 598 Loss: 1.931 | Acc: 24.126% (1442/5977)\n",
      "==> Building model.. beit_base_patch16_224.in22k_ft_in22k   mode  ghost_mixed\n",
      "number of parameters:  85767367\n",
      "Running experiment with: Arguments(learning_rate=0.002, epochs=10, batch_size=500, epsilon=0.5, grad_norm=1, mode='ghost_mixed', model='beit_base_patch16_224.in22k_ft_in22k', mini_batch_size=500, pretrained=1)\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1761/3597 [04:30<04:41,  6.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m     epochs, trainf, testf, save_modelf \u001b[38;5;241m=\u001b[39m prepare(args)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning experiment with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m     train_loss, train_accuracy, test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend([epsilon, grad_norm, mini_bs, train_loss, train_accuracy, test_loss, test_accuracy])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mham_results/results_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mbs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39meps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mgrad_norm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m result_file:\n",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(epochs, trainf, testf, args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(epochs, trainf, testf, args):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 3\u001b[0m         train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrainf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m testf(epoch)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loss, train_accuracy, test_loss, test_accuracy\n",
      "Cell \u001b[0;32mIn[18], line 91\u001b[0m, in \u001b[0;36mprepare.<locals>.train\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m n_acc_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ((batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(trainloader)):\n\u001b[0;32m---> 91\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/private_vision/privacy_engine.py:201\u001b[0m, in \u001b[0;36mPrivacyEngine.attach.<locals>.dp_step\u001b[0;34m(_self, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdp_step\u001b[39m(_self, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    199\u001b[0m     closure \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosure\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 201\u001b[0m     \u001b[43m_self\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprivacy_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     _self\u001b[38;5;241m.\u001b[39moriginal_step(closure\u001b[38;5;241m=\u001b[39mclosure)\n\u001b[1;32m    203\u001b[0m     _self\u001b[38;5;241m.\u001b[39mprivacy_engine\u001b[38;5;241m.\u001b[39munlock()  \u001b[38;5;66;03m# Only enable creating new grads once parameters are updated.\u001b[39;00m\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/venv/lib64/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/private_vision/privacy_engine.py:376\u001b[0m, in \u001b[0;36mPrivacyEngine.step\u001b[0;34m(self, scale, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Step function.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m`loss` must be passed in as a keyword argument!\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mghost_clipping:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ghost_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step(loss\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m), scale\u001b[38;5;241m=\u001b[39mscale)\n",
      "File \u001b[0;32m/s/lovelace/c/nobackup/iray/dp-imgclass/private_vision_clone_2/private_vision/privacy_engine.py:275\u001b[0m, in \u001b[0;36mPrivacyEngine._ghost_step\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    273\u001b[0m     param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39msummed_grad\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_snr:\n\u001b[0;32m--> 275\u001b[0m     signals\u001b[38;5;241m.\u001b[39mappend(\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_multiplier \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    278\u001b[0m     noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnormal(\n\u001b[1;32m    279\u001b[0m         mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    280\u001b[0m         std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_multiplier \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    284\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# class Arguments:\n",
    "#     def __init__(self, learning_rate, epochs, batch_size, epsilon, grad_norm, mode, model, mini_batch_size, pretrained):\n",
    "#         self.lr = learning_rate\n",
    "#         self.epochs = epochs\n",
    "#         self.bs = batch_size\n",
    "#         self.eps = epsilon\n",
    "#         self.grad_norm = grad_norm\n",
    "#         self.mode = mode\n",
    "#         self.model = model\n",
    "#         self.mini_bs = mini_batch_size\n",
    "#         self.pretrained = pretrained\n",
    "#     def __str__(self):\n",
    "#         return f\"Arguments(learning_rate={self.lr}, epochs={self.epochs}, batch_size={self.bs}, epsilon={self.eps}, grad_norm={self.grad_norm}, mode='{self.mode}', model='{self.model}', mini_batch_size={self.mini_bs}, pretrained={self.pretrained})\"\n",
    "\n",
    "# results = [['Epsilon', 'Grad Norm', 'Mini Batch Size', 'Train Loss', 'Train Accuracy', 'Test Loss', 'Test Accuracy']]\n",
    "# epsilons = [0.5, 1, 2]\n",
    "# batch_sizes = [800, 1600]\n",
    "# epochs_to_test = [5, 10]\n",
    "# mini_batches = [10,20]\n",
    "# for batch_size in batch_sizes:\n",
    "#     for epsilon in epsilons:\n",
    "#         for mini_bs in mini_batches:\n",
    "#             for epoch in epochs_to_test:\n",
    "#                 # Modify any additional variables here (or put them into their own loop like above)\n",
    "#                 args = Arguments(learning_rate=2e-3,\n",
    "#                                 epochs=epoch,\n",
    "#                                 batch_size=batch_size,\n",
    "#                                 epsilon=epsilon,\n",
    "#                                 grad_norm=0.5,\n",
    "#                                 mode='ghost_mixed',\n",
    "#                                 model='beit_base_patch16_224.in22k_ft_in22k',\n",
    "#                                 mini_batch_size=mini_bs,\n",
    "#                                 pretrained=1)\n",
    "#                 epochs, trainf, testf, save_modelf = prepare(args)\n",
    "#                 print(f\"Running experiment with: {args}\")\n",
    "#                 train_loss, train_accuracy, test_loss, test_accuracy = main(epochs, trainf, testf, args)\n",
    "#                 results.append([epsilon, grad_norm, mini_bs, train_loss, train_accuracy, test_loss, test_accuracy])\n",
    "#             with open(f\"ham_results/results_{args.bs}_{args.eps}_{args.grad_norm}.json\", 'w') as result_file:\n",
    "#                     result_file.write(json.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5079f9ce-30e4-4b8d-9384-033a5cdaff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f\"ham_results/results_{args.bs}_{args.eps}_{args.grad_norm}.json\", 'w') as result_file:\n",
    "                    result_file.write(json.dumps(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
